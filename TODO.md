# MATH
- base learning rule is belman opt (no learn)
- E -> w/ learning (asymtotic) (w/ learn): show a limit between Loss and E?
- meta-greedy is dual belman opt (no learn)
- Learning does ranks. Ranks ensure an ordering. An order ensures a full search (given time)
- Repeat proofs w/ out opt substructure. Greedy only This must be robust to step-wise learning?

# README

Bellemare, M. G., Schaul, T., Saxton, D., & Ostrovski, G. (2016). Unifying Count-Based Exploration and Intrinsic Motivation, (Nips).
