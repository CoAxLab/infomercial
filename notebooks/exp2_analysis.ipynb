{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 2 analysis\n",
    "\n",
    "See `./informercial/Makefile` for experimental\n",
    "details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "matplotlib.rc('axes', titlesize=16)\n",
    "\n",
    "from infomercial.exp import info_bandit\n",
    "from infomercial.local_gym import bandit\n",
    "from infomercial.exp.info_bandit import load_checkpoint\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ls ../data/exp2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path =\"/Users/qualia/Code/infomercial/data/\"\n",
    "exp_name = \"exp2\"\n",
    "num_exps = 50\n",
    "num_episodes = 10000\n",
    "env_names = [\n",
    "    \"BanditOneHot2-v0\", \n",
    "    \"BanditOneHot10-v0\",\n",
    "    \"BanditOneHot121-v0\",\n",
    "    \"BanditOneHot1000-v0\",\n",
    "    \"BanditOneHigh2-v0\",\n",
    "    \"BanditOneHigh10-v0\",\n",
    "    \"BanditOneHigh121-v0\",\n",
    "    \"BanditOneHigh1000-v0\",\n",
    "    \"BanditHardAndSparse2-v0\",\n",
    "    \"BanditHardAndSparse10-v0\",\n",
    "    \"BanditHardAndSparse121-v0\", \n",
    "    \"BanditHardAndSparse1000-v0\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather traces by bandit: scores, Qs in a big numpy array (n_exp, n_episodes)\n",
    "scores_E = {}\n",
    "scores_R = {}\n",
    "values_E = {}\n",
    "values_R = {}\n",
    "controlling = {}\n",
    "actions = {}\n",
    "best = {}\n",
    "\n",
    "for env in env_names:\n",
    "    # Preallocate the arrays for this env\n",
    "    scores_E[env] = np.zeros((num_episodes, num_exps))\n",
    "    scores_R[env] = np.zeros((num_episodes, num_exps))\n",
    "    values_E[env] = np.zeros((num_episodes, num_exps))\n",
    "    values_R[env] = np.zeros((num_episodes, num_exps))\n",
    "    controlling[env] = np.zeros((num_episodes, num_exps))\n",
    "    actions[env] = np.zeros((num_episodes, num_exps))\n",
    "    best[env] = None\n",
    "    \n",
    "    # Load and repackage\n",
    "    for n in range(num_exps):\n",
    "        result = load_checkpoint(os.path.join(data_path, f\"{exp_name}_{env}_{n+1}.pkl\"))\n",
    "        scores_E[env][:, n] = result[\"scores_E\"]\n",
    "        scores_R[env][:, n] = result[\"scores_R\"]\n",
    "        values_E[env][:, n] = result[\"values_E\"]\n",
    "        values_R[env][:, n] = result[\"values_R\"]\n",
    "        controlling[env][:, n] = result[\"policies\"]\n",
    "        actions[env][:, n] = result[\"actions\"]\n",
    "        best[env] = result[\"best\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BanditOneHot2-v0': 0,\n",
       " 'BanditOneHot10-v0': 7,\n",
       " 'BanditOneHot121-v0': 54,\n",
       " 'BanditOneHot1000-v0': 526,\n",
       " 'BanditOneHigh2-v0': 0,\n",
       " 'BanditOneHigh10-v0': 7,\n",
       " 'BanditOneHigh121-v0': 54,\n",
       " 'BanditOneHigh1000-v0': 526,\n",
       " 'BanditHardAndSparse2-v0': 0,\n",
       " 'BanditHardAndSparse10-v0': 7,\n",
       " 'BanditHardAndSparse121-v0': 54,\n",
       " 'BanditHardAndSparse1000-v0': 526}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scores_E\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather stats by bandit: total R, p_best[-100:-1], Avg score\n",
    "total_R = {}\n",
    "for env in env_names:\n",
    "    total_R[env] = np.zeros(num_exps)\n",
    "    \n",
    "    for n in range(num_exps):\n",
    "        total = scores_R[env][:, n].sum()\n",
    "        total_R[env][n] = total\n",
    "\n",
    "# Est. prob. that the action was correct.\n",
    "p_best = {}\n",
    "for env in env_names:\n",
    "    b = best[env]\n",
    "    p_best[env] = np.zeros(num_episodes)\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        actions_i = actions[env][i,:]\n",
    "        p_best[env][i] = np.sum(actions_i == b) / actions_i.size\n",
    "        \n",
    "# Avg scores\n",
    "avg_scores_E = {}\n",
    "avg_scores_R = {}\n",
    "for env in env_names:\n",
    "    \n",
    "    avg_scores_E[env] = np.zeros(num_episodes)\n",
    "    avg_scores_R[env] = np.zeros(num_episodes)\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        s_E_i = scores_E[env][i,:]\n",
    "        s_R_i = scores_R[env][i,:]\n",
    "        \n",
    "        avg_scores_E[env][i] = s_E_i.mean()\n",
    "        avg_scores_R[env][i] = s_R_i.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_scores_E[env].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning performance\n",
    "\n",
    "For each bandit separatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    }
   ],
   "source": [
    "# For each bandit:\n",
    "# Plot raw actions, with p_best overlaid\n",
    "# Plot scores, avg score overlaid\n",
    "episodes = list(range(num_episodes))\n",
    "tie_threshold = 1e-8\n",
    "\n",
    "# for env in [\"BanditOneHigh1000-v0\"]:\n",
    "for env in env_names:\n",
    "\n",
    "    # ---------------------\n",
    "    # Re-init figure\n",
    "    fig = plt.figure(figsize=(6, 8))\n",
    "    fig.suptitle(f\"{env}\")\n",
    "    grid = plt.GridSpec(3, 1, wspace=0.3, hspace=0.8)\n",
    "    \n",
    "    # ---------------------\n",
    "    # Plot actions\n",
    "    plt.subplot(grid[0, 0])\n",
    "    \n",
    "    b = best[env]\n",
    "    for n in range(num_exps):\n",
    "        a = actions[env][:, n]\n",
    "        plt.scatter(episodes, a, color=\"black\", alpha=.1, s=2, label=\"Bandit\")\n",
    "\n",
    "    # plot best\n",
    "    plt.plot(episodes, np.repeat(b, np.max(episodes)+1), color=\"red\", alpha=0.8, ls='--', linewidth=2)\n",
    "    plt.ylim(-.1, np.max(a)+1.1)\n",
    "    plt.ylabel(\"Arm choice\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    \n",
    "    # ---------------------\n",
    "    # plot p_best\n",
    "    plt.subplot(grid[1, 0])\n",
    "    plt.scatter(episodes, p_best[env], color=\"red\", alpha=0.4, s=2, label=\"E\")\n",
    "    plt.ylim(0,1)\n",
    "    plt.ylabel(\"p(best)\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    \n",
    "    # --------------------\n",
    "    # Plot scores \n",
    "    plt.subplot(grid[2, 0])\n",
    "    for n in range(num_exps):\n",
    "        s_E = scores_E[env][:,n]\n",
    "        s_R = scores_R[env][:,n]\n",
    "        plt.scatter(episodes, s_E, color=\"purple\", alpha=0.01, s=.1)\n",
    "        plt.scatter(episodes, s_R, color=\"grey\", alpha=0.01, s=.1)\n",
    "    \n",
    "    # Add mean\n",
    "#     plt.plot(episodes, avg_scores_E[env], color=\"purple\", alpha=0.8, linewidth=1, label=\"E\")\n",
    "#     plt.plot(episodes, avg_scores_R[env], color=\"grey\", alpha=0.8, linewidth=1, label=\"R\")\n",
    "\n",
    "    # Add epsilon\n",
    "    plt.plot(episodes, np.repeat(tie_threshold, np.max(episodes)+1), \n",
    "             color=\"violet\", alpha=0.8, ls='--', linewidth=2)\n",
    "\n",
    "    plt.ylabel(\"log score\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.semilogy()\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    _ = sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance summary\n",
    "\n",
    "For all bandits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all bandits plot total reward, \n",
    "# with a line added to indicate \n",
    "# the max. exp. total value\n",
    "\n",
    "# Convert to df\n",
    "df_total_R = None\n",
    "\n",
    "sns.boxplot(x=\"env\", y=\"total\", data=df_total_R, palette=\"Set2\")\n",
    "sns.swarmplot(x=\"env\", y=\"total\", data=df_total_R, color=\".25\")\n",
    "_ = sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all bandits plot avg p_best for last 100 episodes\n",
    "\n",
    "# Convert to df\n",
    "df_p_pest = None\n",
    "\n",
    "sns.boxplot(x=\"env\", y=\"p\", data=df_p_pest, palette=\"Set2\")\n",
    "sns.swarmplot(x=\"env\", y=\"p\", data=df_p_pest, color=\".25\")\n",
    "\n",
    "_ = sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
